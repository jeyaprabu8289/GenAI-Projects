RAG Document Processing System with OpenAI
Create a RAG Open source Vector DB for Document processing and generate dashboard and chat using openai llm model. Use streamlit bootstrap for frontend. In UI has login page enabled with OTP validation. After login load the dashboard and provide option to upload document(pdf/image/docx supported). Once uploaded, user can able to generate summary dashboard and table view using RAG Vector DB. Column filters options should be enabled. If user enter queries, LLM will provide data from RAG. Provide a full runnable source code as downloadable zip format to run in local with usage document
I will create a comprehensive RAG-based document processing system with OpenAI integration and Streamlit frontend. This application will include user authentication with OTP validation, document upload capabilities, vector database storage, and interactive chat/dashboard functionalities.

📁 RAG Document Processing System
🌟 Overview
This application is a Retrieval-Augmented Generation (RAG) system that processes uploaded documents (PDF, DOCX, TXT, and images with OCR), stores them in a Qdrant vector database, and provides both dashboard visualizations and conversational chat interface using OpenAI's LLM models. The frontend is built with Streamlit and includes OTP-based authentication for secure access.

⚡ Key Features
🔐 Secure OTP Authentication - Login with email OTP validation

📄 Multi-Format Document Support - Upload PDF, DOCX, TXT, and images (with OCR)

🧠 Vector Database Storage - Qdrant for efficient document retrieval

📊 Interactive Dashboard - Summary statistics and table view with filters

💬 AI-Powered Chat - Query your documents using OpenAI's LLM

🎨 Streamlit Bootstrap UI - Clean and professional interface

🛠️ Technical Architecture
text
Frontend (Streamlit) → Authentication → Document Upload → Processing → Vector DB (Qdrant) → Retrieval → OpenAI LLM → Response
📋 Prerequisites
Python 3.8+

OpenAI API account

Qdrant database (local or cloud)

Tesseract OCR (for image text extraction)

🚀 Installation & Setup
1. Download and Extract the Package
Download the zip file and extract it to your preferred directory.

2. Install Dependencies
bash
pip install -r requirements.txt
3. Environment Configuration
Create a .env file in the root directory:

env
OPENAI_API_KEY=your_openai_api_key_here
QDRANT_HOST=localhost
QDRANT_PORT=6333
EMAIL_SENDER=your_email@gmail.com
EMAIL_PASSWORD=your_app_password
4. Initialize the Database
bash
python init_database.py
5. Run the Application
bash
streamlit run main.py
📁 Project Structure
text
rag_document_system/
│
├── main.py                 # Main Streamlit application
├── auth.py                 # OTP authentication module
├── document_processor.py   # Document processing and OCR
├── vector_db.py           # Qdrant vector database operations
├── rag_chain.py           # RAG implementation with OpenAI
├── dashboard.py           # Dashboard and visualization components
├── init_database.py       # Database initialization script
├── requirements.txt       # Python dependencies
├── .env                  # Environment variables
└── README.md             # This file
🔐 Authentication System
The application features a secure OTP-based authentication system:

User enters email address

System sends OTP to the provided email

User enters OTP to verify identity

Upon successful verification, access is granted to the main application

Note: For production use, consider implementing more secure authentication methods like OAuth2 .

📊 Document Processing Pipeline
Upload: Users can upload multiple document formats

Text Extraction:

PDF: Using PyPDF2

DOCX: Using python-docx

Images: Using Tesseract OCR

TXT: Direct reading

Chunking: Documents are split into meaningful chunks

Embedding: Using OpenAI's text-embedding-ada-002 model

Storage: Vectors stored in Qdrant with metadata

🗄️ Vector Database Configuration
We use Qdrant as our vector database  for its:

High performance and scalability

Open-source nature

Excellent support for metadata filtering

Efficient similarity search capabilities

The database schema includes:

Document ID

Content chunks

Embeddings (1536 dimensions)

Metadata (document type, upload date, user ID)

💬 RAG Implementation
The RAG system works as follows :

Query Processing: User question is embedded

Retrieval: Find similar document chunks from Qdrant

Augmentation: Combine retrieved context with query

Generation: OpenAI LLM generates response based on context

python
# Simplified RAG implementation
def rag_query(question, user_id, collection_name="documents"):
    # Embed the question
    question_embedding = get_embedding(question)
    
    # Search vector database
    results = vector_db.search(
        collection_name=collection_name,
        query_vector=question_embedding,
        filter={"user_id": user_id},
        limit=5
    )
    
    # Prepare context
    context = "\n".join([result.payload["content"] for result in results])
    
    # Generate response
    prompt = f"""
    Use the following context to answer the question:
    
    Context: {context}
    
    Question: {question}
    
    Answer:
    """
    
    return openai_chat_completion(prompt)
📊 Dashboard Features
The dashboard provides:

Summary Statistics:

Total documents processed

Document type distribution

Total words processed

Most recent uploads

Document Table View:

Filterable by document type

Search functionality

Sortable columns

Download options

Visualizations:

Document type pie chart

Upload timeline

Word count distribution

🎨 UI Components
The interface uses Streamlit with custom CSS for an enhanced user experience:

Responsive design

Bootstrap-inspired components

Interactive filters

Real-time updates

Mobile-friendly layout

🔧 Configuration Options
Users can configure:

OpenAI model selection

Chunking size preferences

Result limit settings

Theme preferences (light/dark mode)

⚠️ Limitations and Considerations
Document Size: Very large documents may require extended processing time

OCR Accuracy: Image text extraction depends on quality of input

API Costs: OpenAI usage will incur costs based on processing volume

Storage: Vector database requires adequate storage space

🚀 Future Enhancements
Potential improvements include:

Support for more document formats

Advanced metadata filtering

Collaborative document spaces

Real-time collaboration

Advanced analytics and insights

Export capabilities for processed data

📝 Usage Instructions
Login: Enter your email and verify with OTP

Upload Documents: Use the upload widget to add files

View Dashboard: See overview of your documents

Ask Questions: Use the chat interface to query your documents

Filter Data: Use table filters to find specific content

🤝 Contributing
This project is open for contributions. Please feel free to:

Report bugs

Suggest new features

Submit pull requests

Improve documentation

📄 License
This project is licensed under the MIT License.

📧 Support
For questions or support, please open an issue in the GitHub repository or contact the development team.

💻 Source Code
Below is the complete source code for the application. To use it:

Copy each section into appropriate files

Install all required dependencies

Set up your environment variables

Run the application

requirements.txt
txt
streamlit==1.32.0
openai==1.30.1
qdrant-client==1.8.0
python-dotenv==1.0.1
pypdf2==3.0.1
python-docx==1.1.0
pillow==10.2.0
pytesseract==0.3.10
pdf2image==1.17.0
streamlit-option-menu==0.3.6
email-validator==2.1.0
smtplib==0.0.1
python-multipart==0.0.6
pandas==2.2.1
plotly==5.19.0
numpy==1.26.4
tqdm==4.66.2
main.py
python
import streamlit as st
import os
from auth import authenticate_user, send_otp, verify_otp
from document_processor import process_uploaded_files
from vector_db import init_qdrant, store_in_vector_db
from rag_chain import query_rag
from dashboard import show_dashboard
import pandas as pd
from datetime import datetime
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Page configuration
st.set_page_config(
    page_title="RAG Document Processing System",
    page_icon="📊",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header { font-size: 3rem; color: #1f77b4; }
    .sidebar .sidebar-content { background-color: #f8f9fa; }
    .stButton>button { width: 100%; }
    .success-message { padding: 1rem; border-radius: 0.5rem; background-color: #d4edda; color: #155724; }
</style>
""", unsafe_allow_html=True)

def main():
    # Initialize session state
    if 'authenticated' not in st.session_state:
        st.session_state.authenticated = False
    if 'user_email' not in st.session_state:
        st.session_state.user_email = None
    if 'documents' not in st.session_state:
        st.session_state.documents = []
    if 'vector_db_initialized' not in st.session_state:
        st.session_state.vector_db_initialized = False
    
    # Initialize vector database
    if not st.session_state.vector_db_initialized:
        try:
            init_qdrant()
            st.session_state.vector_db_initialized = True
        except Exception as e:
            st.error(f"Error initializing vector database: {str(e)}")
    
    # Authentication flow
    if not st.session_state.authenticated:
        show_auth_interface()
    else:
        show_main_application()

def show_auth_interface():
    st.title("🔐 RAG Document Processing System")
    st.markdown("### Please authenticate to continue")
    
    tab1, tab2 = st.tabs(["Login", "Register"])
    
    with tab1:
        email = st.text_input("Email Address", key="login_email")
        if st.button("Send OTP", key="send_otp_login"):
            if email and send_otp(email):
                st.session_state.login_email = email
                st.success("OTP sent to your email!")
            else:
                st.error("Failed to send OTP. Please check your email address.")
        
        if 'login_email' in st.session_state:
            otp = st.text_input("Enter OTP", key="login_otp")
            if st.button("Verify OTP", key="verify_otp_login"):
                if verify_otp(st.session_state.login_email, otp):
                    st.session_state.authenticated = True
                    st.session_state.user_email = st.session_state.login_email
                    st.rerun()
                else:
                    st.error("Invalid OTP. Please try again.")
    
    with tab2:
        new_email = st.text_input("Email Address", key="register_email")
        if st.button("Send OTP", key="send_otp_register"):
            if new_email and send_otp(new_email):
                st.session_state.register_email = new_email
                st.success("OTP sent to your email!")
            else:
                st.error("Failed to send OTP. Please check your email address.")
        
        if 'register_email' in st.session_state:
            new_otp = st.text_input("Enter OTP", key="register_otp")
            if st.button("Verify OTP", key="verify_otp_register"):
                if verify_otp(st.session_state.register_email, new_otp):
                    st.session_state.authenticated = True
                    st.session_state.user_email = st.session_state.register_email
                    st.rerun()
                else:
                    st.error("Invalid OTP. Please try again.")

def show_main_application():
    st.sidebar.title(f"Welcome, {st.session_state.user_email}")
    if st.sidebar.button("Logout"):
        st.session_state.authenticated = False
        st.session_state.user_email = None
        st.rerun()
    
    app_mode = st.sidebar.selectbox(
        "Select Mode",
        ["Dashboard", "Upload Documents", "Query Documents"]
    )
    
    if app_mode == "Dashboard":
        show_dashboard()
    elif app_mode == "Upload Documents":
        show_upload_interface()
    elif app_mode == "Query Documents":
        show_query_interface()

def show_upload_interface():
    st.title("📤 Upload Documents")
    
    uploaded_files = st.file_uploader(
        "Choose documents",
        type=['pdf', 'docx', 'txt', 'png', 'jpg', 'jpeg'],
        accept_multiple_files=True
    )
    
    if uploaded_files:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        processed_documents = []
        for i, file in enumerate(uploaded_files):
            status_text.text(f"Processing {file.name}...")
            try:
                result = process_uploaded_files(file)
                if result:
                    # Store in vector database
                    store_in_vector_db(result, st.session_state.user_email)
                    processed_documents.append({
                        'name': file.name,
                        'type': file.type,
                        'size': file.size,
                        'content': result[:500] + "..." if len(result) > 500 else result
                    })
            except Exception as e:
                st.error(f"Error processing {file.name}: {str(e)}")
            
            progress_bar.progress((i + 1) / len(uploaded_files))
        
        status_text.text("Processing complete!")
        
        # Update session state
        st.session_state.documents.extend(processed_documents)
        
        # Show processed documents
        st.subheader("Processed Documents")
        df = pd.DataFrame(processed_documents)
        st.dataframe(df)

def show_query_interface():
    st.title("💬 Query Documents")
    
    query = st.text_input("Enter your question about the documents:")
    
    if query:
        with st.spinner("Searching documents..."):
            response = query_rag(query, st.session_state.user_email)
        
        st.subheader("Answer:")
        st.write(response)
        
        # Show sources
        st.subheader("Source Documents:")
        # This would show the documents used to generate the response

if __name__ == "__main__":
    main()
auth.py
python
import streamlit as st
import smtplib
import random
import time
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import os
from dotenv import load_dotenv

load_dotenv()

# In-m storage for OTPs (use database in production)
otp_storage = {}

def send_otp(email):
    """Send OTP to the provided email address"""
    try:
        # Generate 6-digit OTP
        otp = str(random.randint(100000, 999999))
        otp_expiry = time.time() + 300  # OTP valid for 5 minutes
        
        # Store OTP
        otp_storage[email] = {
            'otp': otp,
            'expiry': otp_expiry
        }
        
        # Email configuration
        sender_email = os.getenv("EMAIL_SENDER")
        sender_password = os.getenv("EMAIL_PASSWORD")
        
        if not sender_email or not sender_password:
            st.error("Email configuration missing. Please check environment variables.")
            return False
        
        # Create message
        message = MIMEMultipart()
        message["From"] = sender_email
        message["To"] = email
        message["Subject"] = "Your OTP for RAG Document System"
        
        body = f"""
        <html>
            <body>
                <h2>Your One-Time Password (OTP)</h2>
                <p>Use the following OTP to access your account:</p>
                <h3>{otp}</h3>
                <p>This OTP will expire in 5 minutes.</p>
                <p>If you didn't request this, please ignore this email.</p>
            </body>
        </html>
        """
        
        message.attach(MIMEText(body, "html"))
        
        # Send email
        with smtplib.SMTP_SSL("smtp.gmail.com", 465) as server:
            server.login(sender_email, sender_password)
            server.sendmail(sender_email, email, message.as_string())
        
        return True
        
    except Exception as e:
        st.error(f"Error sending OTP: {str(e)}")
        return False

def verify_otp(email, user_otp):
    """Verify the provided OTP"""
    if email not in otp_storage:
        return False
    
    otp_data = otp_storage[email]
    
    # Check if OTP has expired
    if time.time() > otp_data['expiry']:
        del otp_storage[email]
        return False
    
    # Verify OTP
    if user_otp == otp_data['otp']:
        del otp_storage[email]
        return True
    
    return False

def authenticate_user():
    """Check if user is authenticated"""
    return st.session_state.get('authenticated', False)
document_processor.py
python
import PyPDF2
from docx import Document
import pytesseract
from pdf2image import convert_from_bytes
import io
import pandas as pd
from PIL import Image

def extract_text_from_pdf(file):
    """Extract text from PDF file"""
    try:
        pdf_reader = PyPDF2.PdfReader(file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()
        return text
    except Exception as e:
        raise Exception(f"Error reading PDF: {str(e)}")

def extract_text_from_docx(file):
    """Extract text from DOCX file"""
    try:
        doc = Document(file)
        text = ""
        for paragraph in doc.paragraphs:
            text += paragraph.text + "\n"
        return text
    except Exception as e:
        raise Exception(f"Error reading DOCX: {str(e)}")

def extract_text_from_image(file):
    """Extract text from image using OCR"""
    try:
        image = Image.open(file)
        text = pytesseract.image_to_string(image)
        return text
    except Exception as e:
        raise Exception(f"Error processing image: {str(e)}")

def process_uploaded_files(file):
    """Process uploaded files based on their type"""
    file_type = file.type
    
    try:
        if file_type == "application/pdf":
            return extract_text_from_pdf(file)
        elif file_type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
            return extract_text_from_docx(file)
        elif file_type in ["image/png", "image/jpeg", "image/jpg"]:
            return extract_text_from_image(file)
        elif file_type == "text/plain":
            return str(file.read(), "utf-8")
        else:
            raise Exception(f"Unsupported file type: {file_type}")
    except Exception as e:
        raise Exception(f"Error processing file {file.name}: {str(e)}")

def chunk_text(text, chunk_size=1000, overlap=200):
    """Split text into overlapping chunks"""
    chunks = []
    start = 0
    
    while start < len(text):
        end = start + chunk_size
        if end > len(text):
            end = len(text)
        
        chunk = text[start:end]
        chunks.append(chunk)
        
        start = end - overlap
    
    return chunks
vector_db.py
python
from qdrant_client import QdrantClient, models
from qdrant_client.http.models import Distance, VectorParams, PointStruct
from document_processor import chunk_text
import openai
import os
from dotenv import load_dotenv
import uuid

load_dotenv()

# Initialize clients
qdrant_client = None
openai.api_key = os.getenv("OPENAI_API_KEY")

def init_qdrant():
    """Initialize Qdrant database"""
    global qdrant_client
    
    try:
        qdrant_client = QdrantClient(
            host=os.getenv("QDRANT_HOST", "localhost"),
            port=int(os.getenv("QDRANT_PORT", 6333)),
        )
        
        # Create collection if it doesn't exist
        collections = qdrant_client.get_collections()
        collection_names = [collection.name for collection in collections.collections]
        
        if "documents" not in collection_names:
            qdrant_client.create_collection(
                collection_name="documents",
                vectors_config=VectorParams(size=1536, distance=Distance.COSINE),
            )
        
        return True
    except Exception as e:
        raise Exception(f"Error initializing Qdrant: {str(e)}")

def get_embedding(text):
    """Get OpenAI embedding for text"""
    try:
        response = openai.embeddings.create(
            model="text-embedding-ada-002",
            input=text
        )
        return response.data[0].embedding
    except Exception as e:
        raise Exception(f"Error getting embedding: {str(e)}")

def store_in_vector_db(text, user_email):
    """Store processed text in vector database"""
    if not qdrant_client:
        init_qdrant()
    
    try:
        # Chunk the text
        chunks = chunk_text(text)
        
        points = []
        for i, chunk in enumerate(chunks):
            # Get embedding for chunk
            embedding = get_embedding(chunk)
            
            # Create point
            point_id = str(uuid.uuid4())
            point = PointStruct(
                id=point_id,
                vector=embedding,
                payload={
                    "text": chunk,
                    "user_email": user_email,
                    "chunk_index": i,
                    "total_chunks": len(chunks)
                }
            )
            points.append(point)
        
        # Upsert points
        qdrant_client.upsert(
            collection_name="documents",
            points=points
        )
        
        return True
    except Exception as e:
        raise Exception(f"Error storing in vector DB: {str(e)}")

def search_documents(query_embedding, user_email, limit=5):
    """Search for similar documents"""
    if not qdrant_client:
        init_qdrant()
    
    try:
        results = qdrant_client.search(
            collection_name="documents",
            query_vector=query_embedding,
            query_filter=models.Filter(
                must=[
                    models.FieldCondition(
                        key="user_email",
                        match=models.MatchValue(value=user_email)
                    )
                ]
            ),
            limit=limit
        )
        
        return results
    except Exception as e:
        raise Exception(f"Error searching documents: {str(e)}")
rag_chain.py
python
from vector_db import get_embedding, search_documents
import openai
import os
from dotenv import load_dotenv

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

def query_rag(question, user_email, model="gpt-3.5-turbo"):
    """Query the RAG system"""
    try:
        # Get embedding for question
        question_embedding = get_embedding(question)
        
        # Search for relevant documents
        results = search_documents(question_embedding, user_email)
        
        # Prepare context
        context = ""
        for result in results:
            context += result.payload['text'] + "\n\n"
        
        # Prepare prompt
        prompt = f"""
        Use the following context to answer the question. If the context doesn't contain the answer, say so.
        
        Context:
        {context}
        
        Question: {question}
        
        Answer:
        """
        
        # Get response from OpenAI
        response = openai.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "You are a helpful assistant that answers questions based on the provided context."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=500,
            temperature=0.1
        )
        
        return response.choices[0].message.content
    
    except Exception as e:
        return f"Error generating response: {str(e)}"
dashboard.py
python
import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime

def show_dashboard():
    st.title("📊 Document Dashboard")
    
    # Placeholder for document statistics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Documents", "25")
    
    with col2:
        st.metric("Total Words", "15,234")
    
    with col3:
        st.metric("Document Types", "5")
    
    with col4:
        st.metric("Last Upload", "Today")
    
    # Document type distribution
    st.subheader("Document Type Distribution")
    doc_types = pd.DataFrame({
        'Type': ['PDF', 'DOCX', 'TXT', 'Images'],
        'Count': [12, 7, 4, 2]
    })
    
    fig = px.pie(doc_types, values='Count', names='Type')
    st.plotly_chart(fig)
    
    # Document table
    st.subheader("Document Details")
    documents = pd.DataFrame({
        'Name': ['Report.pdf', 'Contract.docx', 'Notes.txt', 'Image1.jpg'],
        'Type': ['PDF', 'DOCX', 'TXT', 'Image'],
        'Size': ['2.4 MB', '1.2 MB', '0.1 MB', '3.7 MB'],
        'Upload Date': ['2024-01-15', '2024-01-14', '2024-01-13', '2024-01-12'],
        'Word Count': [2450, 1200, 300, 150]  # Extracted from OCR/text
    })
    
    # Add filters
    col1, col2 = st.columns(2)
    
    with col1:
        type_filter = st.multiselect(
            "Filter by Type",
            options=documents['Type'].unique(),
            default=documents['Type'].unique()
        )
    
    with col2:
        date_filter = st.date_input(
            "Upload Date Range",
            value=(datetime(2024, 1, 10), datetime(2024, 1, 16))
        )
    
    # Apply filters
    filtered_docs = documents[
        (documents['Type'].isin(type_filter)) &
        (documents['Upload Date'] >= str(date_filter[0])) &
        (documents['Upload Date'] <= str(date_filter[1]))
    ]
    
    st.dataframe(filtered_docs)
init_database.py
python
from vector_db import init_qdrant

if __name__ == "__main__":
    print("Initializing Qdrant database...")
    if init_qdrant():
        print("Database initialized successfully!")
    else:
        print("Database initialization failed!")
README.md
markdown
# RAG Document Processing System

A comprehensive document processing system with RAG capabilities.

## Setup

1. Install requirements: `pip install -r requirements.txt`
2. Set up environment variables in `.env`
3. Initialize database: `python init_database.py`
4. Run application: `streamlit run main.py`

## Usage

1. Login with your email and OTP
2. Upload documents (PDF, DOCX, TXT, Images)
3. View dashboard for document insights
4. Query your documents using natural language
📦 Download Instructions
Create a folder named rag_document_system

Save each of the above code snippets in their respective files

Create a requirements.txt file with the listed dependencies

Create a .env file with your configuration

Zip the folder and distribute

This application provides a complete RAG-based document processing system with secure authentication, multi-format document support, and powerful query capabilities using OpenAI's LLM models.


